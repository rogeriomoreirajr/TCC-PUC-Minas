{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Coleta e Tratamento Inicial dos Dados.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hCISDM_Fz0Fm",
        "0UQbpral29kN",
        "LWijLxdz9MM5",
        "I-u56WIfT_Gz",
        "k1vrJmL-N4Vl",
        "u4L4MLKNTtWo"
      ],
      "mount_file_id": "1lnQ_VSKkdLmKvP6k1gm5tP0EMKcFRcpe",
      "authorship_tag": "ABX9TyORV7IJSnqv12jBVrQdUfJT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogeriomoreirajr/TCC-PUC-Minas/blob/master/2_Coleta_e_Tratamento_Inicial_dos_Dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr9xXPQ_M2C5",
        "colab_type": "text"
      },
      "source": [
        "# Dados\n",
        "\n",
        "Este notebook contém os scripts usados para capturar, tratar e salvar os dados usados no TCC\n",
        "\n",
        "## Parâmetros\n",
        "- Todas as datas salvas como datetime\n",
        "- Preços como floats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5yOY0edNGUA",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Preço do combustível\n",
        "\n",
        "> - Dados semanais (baseados no Excel, os municipais, estaduais e nacionais)\n",
        "- Dados dos postos (conseguidos pelo preco.anp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0nIxpcAUqO7",
        "colab_type": "text"
      },
      "source": [
        "### Dados semanais\n",
        "Semanalmente a ANP promove uma pesquisa nos postos de combustível para acompanhar os preços praticados. Um dos objetivos é poder checar se os postos não estão com alguma prática que possa prejudicar o consumidor (como cartéis). Como é de de imaginar (dado o tamanho continental do Brasil) essa pesquisa é feita por amostragem, em 459 municípios dos 27 estados e do Distrito Federal.\n",
        "\n",
        "Os dados são publicados no site da autarquia de duas formas:\n",
        "- Séries históricas: tabelas onde cada linha representa o resultado da pesquisa semanal para cada abrangência (municipal, estadual, regional ou nacional). São tabelas de excel, com os valores mais antigos datando de 2004. Cada linha traz dados como o preço máximo, médio e mínimo de revenda, além do desvio padrão (entre outros).\n",
        "- Levantamento de preço: uma interface que permite buscar os resultados da última coleta, por município e estado. Através de requisições diretas ao servidor é possível ter os dados das últimas dez coletas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCISDM_Fz0Fm",
        "colab_type": "text"
      },
      "source": [
        "#### Dados de município"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytXQckf4VD3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Essa biblioteca abre os arquivos xlsb, um arquivo binário do Excel\n",
        "!pip install pyxlsb\n",
        "from pyxlsb import open_workbook as open_xlsb\n",
        "\n",
        "# As tabelas estão disponíveis em http://www.anp.gov.br/precos-e-defesa-da-concorrencia/precos/levantamento-de-precos/serie-historica-do-levantamento-de-precos-e-de-margens-de-comercializacao-de-combustiveis\n",
        "# O que fiz aqui foi salvá-las localmente (no caso, no Google Drive, montado no\n",
        "# Google Colab) e lê-las a partir daí, como arquivos locais.\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/raw/anp'\n",
        "os.chdir(path)\n",
        "files = os.listdir()\n",
        "\n",
        "# Separo em duas listas: uma com os xlsb e outra com xlsx\n",
        "# Isso é necessário porque o xlsb não é suportado pelo pandas,\n",
        "# e precisa de outro tratamento.\n",
        "files_xlsb = [el for el in files if el.endswith('xlsb')]\n",
        "files_xlsx = [el for el in files if el.endswith('xlsx')]\n",
        "\n",
        "list_dfs = []\n",
        "\n",
        "# A função abaixo abre o xlsb, desde que a gente dê a linha do cabeçalho\n",
        "\n",
        "def xlsb2pandas(file, header):\n",
        "    \"\"\"\n",
        "    file: caminho para o arquivo\n",
        "    header: linha onde está o cabeçalho\n",
        "    \"\"\"\n",
        "    values = []\n",
        "\n",
        "    with open_xlsb(file) as wb:\n",
        "        with wb.get_sheet(1) as sheet:\n",
        "            for row in sheet.rows():\n",
        "                values.append([item.v for item in row])\n",
        "\n",
        "    df_ = pd.DataFrame(values[header+1:])\n",
        "\n",
        "    # Transformar a data de cinco dígitos em datetime\n",
        "    df_[0] = df_[0].apply(lambda x:(datetime(1899, 12, 30) + timedelta(days= x )))\n",
        "    df_[1] = df_[1].apply(lambda x:(datetime(1899, 12, 30) + timedelta(days= x )))\n",
        "\n",
        "    headers = values[header]\n",
        "    df_.columns = headers\n",
        "\n",
        "    return df_\n",
        "\n",
        "\n",
        "df_ = xlsb2pandas(files_xlsb[0], 12)\n",
        "list_dfs.append(df_)\n",
        "\n",
        "df_ = xlsb2pandas(files_xlsb[1], 14)\n",
        "list_dfs.append(df_)\n",
        "\n",
        "\n",
        "# Dados recentes\n",
        "for file in files_xlsx:\n",
        "    skip = 12\n",
        "    if file  == 'SEMANAL_MUNICIPIOS-2018.xlsx':\n",
        "        # Tem uma observação no arquivo de 2018, logo uma linha a mais\n",
        "        skip = 13\n",
        "    \n",
        "    df_ = pd.read_excel(file, skiprows=\tskip)\n",
        "    list_dfs.append(df_)\n",
        "\n",
        "# Um df com todos os dados\n",
        "df_mun = pd.concat(list_dfs, ignore_index=True)\n",
        "\n",
        "df_mun.columns = [\n",
        " 'data_inicial',\n",
        " 'data_final',\n",
        " 'regiao',\n",
        " 'estado',\n",
        " 'municipio',\n",
        " 'produto',\n",
        " 'número_postos_pesquisados',\n",
        " 'unidade_medida',\n",
        " 'preço_medio_revenda',\n",
        " 'desvio_padrao_revenda',\n",
        " 'preço_minimo_revenda',\n",
        " 'preço_máximo_revenda',\n",
        " 'margem_media_revenda',\n",
        " 'coef_variaçao_revenda',\n",
        " 'preço_medio_distribuiçao',\n",
        " 'desvio_padrao_distribuiçao',\n",
        " 'preço_minimo_distribuiçao',\n",
        " 'preço_máximo_distribuiçao',\n",
        " 'coef_variaçao_distribuiçao']\n",
        "\n",
        "select = ['data_inicial',\n",
        " 'data_final',\n",
        " 'regiao',\n",
        " 'estado',\n",
        " 'municipio',\n",
        " 'preço_medio_revenda',\n",
        " 'preço_minimo_revenda',\n",
        " 'preço_máximo_revenda',]\n",
        "\n",
        "df_mun = df_mun[df_mun.produto == 'GASOLINA COMUM'][select]\n",
        "\n",
        "# Algumas datas estão em formato numérico\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/'\n",
        "df_mun.to_csv(path+'/anp_municipios.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UQbpral29kN",
        "colab_type": "text"
      },
      "source": [
        "#### Dados nacionais, regionais e estaduais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8vSkhUX5Id-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "url = 'http://www.anp.gov.br/precos-e-defesa-da-concorrencia/precos/levantamento-de-precos/serie-historica-do-levantamento-de-precos-e-de-margens-de-comercializacao-de-combustiveis'\n",
        "root = 'http://www.anp.gov.br/'\n",
        "\n",
        "soup = BeautifulSoup(requests.get(url).content)\n",
        "\n",
        "def not_city(link):\n",
        "    href = link['href']\n",
        "    if href.endswith('xlsx'):\n",
        "        if 'MUNICIPIO' not in href:\n",
        "            if 'SEMANAL' in href or 'Semanal' in href:\n",
        "                return True   \n",
        "        \n",
        "links = [el['href'] for el in soup.findAll('a') if not_city(el)]\n",
        "\n",
        "list_dfs = []\n",
        "\n",
        "for file in links:\n",
        "    df_ = pd.read_excel(root+file)\n",
        "\n",
        "    # achar o cabeçalho\n",
        "    ix = df_[df_.iloc[0:,0] == 'DATA INICIAL'].index[0]\n",
        "    df_ = pd.read_excel(root+file, skiprows=ix, header=1)\n",
        "    \n",
        "    list_dfs.append(df_)\n",
        "\n",
        "df = pd.concat(list_dfs, ignore_index=True, sort=False)\n",
        "\n",
        "\n",
        "def tipo_dado(row):\n",
        "    \"\"\"\n",
        "    Essa função analisa se a linha pertence a um dado nacional, estadual ou regional\n",
        "    \"\"\"\n",
        "    if pd.isnull(row['REGIÃO']) and  pd.isnull(row['ESTADO']):\n",
        "        return 'nacional'\n",
        "    elif not pd.isnull(row['REGIÃO']) and pd.isnull(row['ESTADO']):\n",
        "        return 'regional'\n",
        "    elif not pd.isnull(row['REGIÃO']) and not pd.isnull(row['ESTADO']):\n",
        "        return 'estadual'\n",
        "\n",
        "df['abrangencia'] = df.apply(tipo_dado, axis=1)  \n",
        "\n",
        "df.columns = ['data_inicial',\n",
        " 'data_final',\n",
        " 'produto',\n",
        " 'número_de_postos_pesquisados',\n",
        " 'unidade_de_medida',\n",
        " 'preco_medio_revenda',\n",
        " 'desvio_padrao_revenda',\n",
        " 'preco_minimo_revenda',\n",
        " 'preco_maximo_revenda',\n",
        " 'margem_media_revenda',\n",
        " 'coef_de_variacao_revenda',\n",
        " 'preco_medio_distribuicao',\n",
        " 'desvio_padrao_distribuicao',\n",
        " 'preco_minimo_distribuicao',\n",
        " 'preco_maximo_distribuicao',\n",
        " 'coef_de_variacao_distribuicao',\n",
        " 'regiao',\n",
        " 'estado',\n",
        " 'abrangencia']\n",
        "\n",
        "not_include = [ 'margem_media_revenda',\n",
        " 'produto',\n",
        " 'número_de_postos_pesquisados',\n",
        " 'unidade_de_medida',\n",
        " 'coef_de_variacao_revenda',\n",
        " 'preco_medio_distribuicao',\n",
        " 'desvio_padrao_distribuicao',\n",
        " 'preco_minimo_distribuicao',\n",
        " 'preco_maximo_distribuicao',\n",
        " 'coef_de_variacao_distribuicao',\n",
        "]\n",
        "\n",
        "columns = [el for el in df.columns if el not in not_include]\n",
        "\n",
        "df_abrangencia = df[df.produto == 'GASOLINA COMUM'][columns]\n",
        "\n",
        "for data in ['data_final','data_inicial']:\n",
        "    df[data] = pd.to_datetime(df_abrangencia[data])\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/'\n",
        "df_abrangencia.to_csv(path+'anp_abrangencias.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWijLxdz9MM5",
        "colab_type": "text"
      },
      "source": [
        "### Dados dos postos\n",
        "A ANP divulga no site http://preco.anp.gov.br/ o resultado da última coleta em cada município, através do sistema de busca. Para conseguir os dados de outras semanas (as últimas dez, que são as que estão disponíveis) eu fiz um script que faz o scrape no site, mandando uma requisição POST e tratando os dados que o site retorna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BX-Gtvzz9MZ",
        "colab_type": "code",
        "outputId": "3c276a35-0244-446e-9957-baf281f8fb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "\"\"\"\n",
        "Ele não tem dados de muitas semanas atrás?\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/raw'\n",
        "os.chdir(path)\n",
        "\n",
        "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
        "headers = {'User-Agent': user_agent}\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "url = 'http://preco.anp.gov.br/include/Relatorio_Excel_Semanal_Posto.asp'\n",
        "\n",
        "# Cidades ao redor de Belo Horizonte\n",
        "cidades = {\n",
        "    2762: \"Betim\",\n",
        "    2980: \"Contagem\",\n",
        "    2754: \"Belo Horizonte\",\n",
        "    3724: \"Sabará\",\n",
        "    3480: \"Nova Lima\",\n",
        "}\n",
        "\n",
        "# Dados universais sobre os combustiveis\n",
        "combustiveis = {\n",
        "    '487':'gasolina',\n",
        "    '532':'diesel', \n",
        "    }\n",
        "\n",
        "data = {\n",
        "    'btnSalvar':'Exportar',\n",
        "    'COD_SEMANA': None,\n",
        "    'COD_COMBUSTIVEL': None, \n",
        "    'COD_MUNICIPIO': None, \n",
        "    }\n",
        "\n",
        "# Valor da semana atual\n",
        "url = 'http://preco.anp.gov.br/include/Resumo_Por_Municipio_Index.asp'\n",
        "soup_ = BeautifulSoup(requests.get(url).content)\n",
        "end = soup_.find('form',{'id':'frmAberto'}).find('input',{'name':'cod_Semana'})['value']\n",
        "\n",
        "\n",
        "url = 'http://preco.anp.gov.br/include/Relatorio_Excel_Semanal_Posto.asp'\n",
        "\n",
        "# Último valor lido\n",
        "file_ = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/preços nos postos.csv'\n",
        "start = pd.read_csv(file_).ix_semana.max()\n",
        "\n",
        "semanas = range(start+1, int(end)+1)\n",
        "\n",
        "l_precos = []\n",
        "\n",
        "for cidade in cidades:\n",
        "    data['COD_MUNICIPIO'] = cidade\n",
        "    \n",
        "    n_cidade = cidades[cidade]\n",
        "    print(n_cidade)\n",
        "\n",
        "    for combustivel in combustiveis:\n",
        "        data['COD_COMBUSTIVEL'] = combustivel\n",
        "        \n",
        "        n_combustivel = combustiveis[combustivel]\n",
        "        print('>>>'+n_combustivel, end='\\t')\n",
        "\n",
        "        for semana in semanas:\n",
        "            print('.', end='')\n",
        "\n",
        "            data['COD_SEMANA'] = semana\n",
        "            content = requests.post(\n",
        "                url, \n",
        "                data = data,\n",
        "                headers=headers).content\n",
        "\n",
        "            soup = BeautifulSoup(content)\n",
        "\n",
        "            tabelas = pd.read_html(str(soup))\n",
        "\n",
        "            def loc_df(df):\n",
        "                df['combustivel'] = n_combustivel\n",
        "                df['cidade'] = n_cidade\n",
        "                df['ix_semana'] = semana\n",
        "\n",
        "            df_precos = tabelas[1]\n",
        "            loc_df(df_precos)\n",
        "            l_precos.append(df_precos)\n",
        "\n",
        "        print(' fim')\n",
        "\n",
        "\n",
        "df = pd.concat(l_precos)\n",
        "\n",
        "def one_level(tuple):\n",
        "    \"\"\"\n",
        "    # A tabela que vem do site vem com dois níveis de colunas. \n",
        "    Essa função deixa em um nível\n",
        "    \"\"\"\n",
        "    if tuple[1] == '': return tuple[0]\n",
        "    else: return tuple[1]\n",
        "\n",
        "df.columns = [one_level(el) for el in df.columns]\n",
        "\n",
        "df.rename( columns=\n",
        "{'BAIRRO': 'bairro',\n",
        " 'BANDEIRA': 'bandeira',\n",
        " 'DATA COLETA': 'data',\n",
        " 'ENDEREÇO': 'endereco',\n",
        " 'FORNECEDOR (B BRANCA)': 'fornecedor',\n",
        " 'MODELIDADE DE COMPRA': 'modalidade',\n",
        " 'PREÇO COMPRA': 'compra',\n",
        " 'PREÇO VENDA': 'venda',\n",
        " 'RAZÃO SOCIAL': 'razao',\n",
        " 'cidade': 'cidade',\n",
        " 'combustivel': 'combustivel',\n",
        " 'ix_semana': 'ix_semana'}, inplace=True)\n",
        "\n",
        "df.venda = df.venda.astype(int)/1000\n",
        "\n",
        "df_old = pd.read_csv(file_)\n",
        "df_old = df_old.iloc[:,1:]\n",
        "\n",
        "df_postos = pd.concat([df, df_old])\n",
        "\n",
        "df_postos.to_csv('anp_preços nos postos.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2379810fbff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'user_agent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-u56WIfT_Gz",
        "colab_type": "text"
      },
      "source": [
        "## 2.2. Preço do barril de Petróleo Brent\n",
        "\n",
        "Preço do barril do patróleto Brent, recuperados direto do site da Nasdaq. Valores a partir de 2007.\n",
        "\n",
        "ler: https://www.nasdaq.com/articles/how-do-crude-oil-prices-affect-oil-stocks-2016-08-14\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp6-2jtV1Sx_",
        "colab_type": "code",
        "outputId": "930e178c-9265-4b56-a948-72f20b96acd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/'\n",
        "\n",
        "url = 'https://www.nasdaq.com/api/v1/historical/BZ:NMX/commodities/2004-01-01/2020-03-30'\n",
        "\n",
        "df_barril = pd.read_csv(url)[['Date',' Close/Last']]\n",
        "df_barril.columns = ['data','close']\n",
        "\n",
        "df_barril.data = pd.to_datetime(df_barril.data)\n",
        "\n",
        "df_barril.to_csv(path+'nasdaq_preco barril.csv', index=False)\n",
        "\n",
        "df_barril"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-27</td>\n",
              "      <td>24.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-26</td>\n",
              "      <td>26.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-25</td>\n",
              "      <td>27.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-24</td>\n",
              "      <td>27.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-23</td>\n",
              "      <td>27.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3084</th>\n",
              "      <td>2007-11-23</td>\n",
              "      <td>95.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3085</th>\n",
              "      <td>2007-11-21</td>\n",
              "      <td>94.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3086</th>\n",
              "      <td>2007-11-20</td>\n",
              "      <td>95.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3087</th>\n",
              "      <td>2007-11-19</td>\n",
              "      <td>92.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3088</th>\n",
              "      <td>2007-11-16</td>\n",
              "      <td>91.58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3089 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           data  close\n",
              "0    2020-03-27  24.93\n",
              "1    2020-03-26  26.34\n",
              "2    2020-03-25  27.39\n",
              "3    2020-03-24  27.15\n",
              "4    2020-03-23  27.03\n",
              "...         ...    ...\n",
              "3084 2007-11-23  95.70\n",
              "3085 2007-11-21  94.95\n",
              "3086 2007-11-20  95.43\n",
              "3087 2007-11-19  92.37\n",
              "3088 2007-11-16  91.58\n",
              "\n",
              "[3089 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1vrJmL-N4Vl",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Câmbio do dólar\n",
        "Estou usando os dados do Banco Central do Brasil, através do Ipeadata (base de dados públicos gerenciada pelo Instituto de Pesquisa Econômica Aplicada, fundação pública federal vinculada ao Ministério da Economia. No caso, estou usando a média do dia da taxa de câmbio real/dólar comercial (valor de compra). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StbCHZFyMzWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'http://ipeadata.gov.br/ExibeSerie.aspx?serid=38590&module=M'\n",
        "df_dolar = pd.read_html(url, skiprows=1)[0]\n",
        "df_dolar.columns = ['data','cambio']\n",
        "\n",
        "# data como datetime\n",
        "df_dolar.data = pd.to_datetime(df_dolar.data, format='%d/%m/%Y')\n",
        "\n",
        "# Só queremos os dados a partir de 2004\n",
        "df_dolar = df_dolar[df_dolar.data>'2004-01-01']\n",
        "\n",
        "# cambio de str para float\n",
        "df_dolar.cambio = df_dolar.cambio.astype(int) / 10000\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data'\n",
        "\n",
        "df_dolar.to_csv(path + '/dolar.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NnHDKisTxDK",
        "colab_type": "text"
      },
      "source": [
        "## 2.4. Cesta básica\n",
        "\n",
        "Os dados vem do DIEESE. Ele permite que sejam baixados num xls. Tenho, no arquivo baixado, os dados a partir de 2004"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLPCapb4TijO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/raw/cesta basica dieese.xls'\n",
        "\n",
        "df_cesta = pd.read_excel(path, skiprows=1, skipfooter=2)\n",
        "df_cesta = df_cesta.melt(id_vars = 'Unnamed: 0', \n",
        "                        var_name = 'abrangencia', \n",
        "                        value_name='valor')\n",
        "\n",
        "df_cesta.columns = ['data', 'abrangencia', 'valor']\n",
        "\n",
        "df_cesta.data = df_cesta.data.str.extract('(\\d+-\\d+)')\n",
        "df_cesta.data = pd.to_datetime(df_cesta.data, format='%m-%Y')\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data'\n",
        "df_cesta.to_csv(path + '/cesta basica.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNVqroawN203",
        "colab_type": "text"
      },
      "source": [
        "## 2.5. Inflação IPCA\n",
        "\n",
        "O combustível é um dos subitems do IPCA. O IBGE tem os dados desses subitens de mês em mês, no site deles (e num servidor ftp). É importante ter o script que busca os dados no servidor do IBGE e os salva no nosso servidor para facilitar que outras pessoas possam refazer os meus passos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5nI_l0jks3I",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from io import StringIO, BytesIO\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\"\"\"\n",
        "A parte de baixo desse código é para fazer tudo o que eu fiz, mas via ftp.\n",
        "Ainda não está implementada. Usei os arquivos locais.\n",
        "\"\"\"\n",
        "# !pip install ftputil\n",
        "# import ftputil\n",
        "\n",
        "# host = ftputil.FTPHost('ftp.ibge.gov.br','anonymous','')\n",
        "# path = 'Precos_Indices_de_Precos_ao_Consumidor/IPCA/Resultados_por_Subitem'\n",
        "# host.chdir(path)\n",
        "# for folder in [el for el in host.listdir('') if host.path.isdir(el)]:\n",
        "#     print(folder)\n",
        "#     for file in host.listdir(folder):\n",
        "#         print('\\t'+file)\n",
        "#         host.download(folder+'/'+file, 'ipca/{}/{}/'.format(folder, file))\n",
        "\n",
        "p = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/raw/ipca/'\n",
        "\n",
        "os.chdir(p)\n",
        "folders = [el for el in os.listdir() if os.path.isdir(el)]\n",
        "\n",
        "lista_abas = {}\n",
        "\n",
        "for folder in folders:\n",
        "    print(folder)\n",
        "\n",
        "    # Para cada pasta no diretório, ele caminha e alimenta o `lista abas` \n",
        "    # com o conteúdo das planilhas\n",
        "    os.chdir(folder)\n",
        "    files = os.listdir()\n",
        "    for file_ in files:\n",
        "        with ZipFile(file_) as myzip:\n",
        "            excel_file = myzip.namelist()[0]\n",
        "            with myzip.open(excel_file) as myfile:\n",
        "                print('...'+excel_file)\n",
        "\n",
        "                # Essa foi a forma de abrir o arquivo:\n",
        "                # transformar ele num objeto ExcelFile\n",
        "                df = pd.ExcelFile(BytesIO(myfile.read()))\n",
        "                df = df.parse(sheet_name=None)\n",
        "\n",
        "                lista_abas[excel_file] = df\n",
        "    \n",
        "    # Ele volta para o diretório raiz\n",
        "    os.chdir('..')\n",
        "\n",
        "list_ipca = []\n",
        "\n",
        "indices = ('Índice Geral',\n",
        "           'ÍNDICE GERAL',\n",
        "           'INDICE GERAL',\n",
        "           ' ÍNDICE GERAL')\n",
        "\n",
        "# Como o Google Colab não tem um locale, tive que criar esse dicionário\n",
        "# Para transformar as datas em datetime\n",
        "meses = {'Abril': 'April',\n",
        " 'Agosto': 'August',\n",
        " 'Dezembro': 'December',\n",
        " 'Fevereiro': 'February',\n",
        " 'Janeirro': 'January',\n",
        " 'Janeiro': 'January',\n",
        " 'Julho': 'July',\n",
        " 'Junho': 'June',\n",
        " 'Maio': 'May',\n",
        " 'Março': 'March',\n",
        " 'Novembro': 'November',\n",
        " 'Outubro': 'October',\n",
        " 'Setembro': 'September'}\n",
        "\n",
        "def limpa_periodo(string):\n",
        "    \"\"\"\n",
        "    Função para transformar a data do período em datetime\n",
        "    \"\"\"\n",
        "    string = re.sub('[- ]*IPCA[^ ]*[- ]*','', string)\n",
        "    string = re.sub('(^ | $)','', string)\n",
        "    string = string.title()\n",
        "    # string = string.replace(meses)\n",
        "    for mes, month in meses.items():\n",
        "        string = string.replace(mes, month)\n",
        "\n",
        "    string = re.sub(' De ', ' ', string)\n",
        "\n",
        "    dt_string = pd.to_datetime(string, format='%B %Y')\n",
        "\n",
        "    # transformar em datetime\n",
        "    return dt_string\n",
        "\n",
        "# Preciso tirar uma aba específica: 'RELATÓRIO (FÓRMULA E PREENCHER '\n",
        "\n",
        "for planilha in lista_abas:\n",
        "    for aba in lista_abas[planilha]:\n",
        "        if 'RELATÓRIO' in aba or 'MENSAL SUBITEM IPCA' in aba:\n",
        "            df = lista_abas[planilha][aba].dropna(how='all').reset_index(drop=True)\n",
        "            primeiro_index = df[df.iloc[:,0].isin(indices)].index\n",
        "            if not primeiro_index.empty:\n",
        "                primeira_linha, = primeiro_index.values\n",
        "                ix_headers = primeira_linha-1\n",
        "                headers = df.iloc[ix_headers]\n",
        "                headers[0] = 'categoria'\n",
        "                df.columns = headers.values\n",
        "\n",
        "                # ll.append(df.iloc[ix_headers-1,0])\n",
        "                periodo = df.iloc[ix_headers-1,0]\n",
        "\n",
        "                # tirar os valores sobre o cabeçalho\n",
        "                df = df.iloc[ix_headers+1:]\n",
        "                df['periodo'] = limpa_periodo(periodo)\n",
        "\n",
        "                # tirar colunas nulas\n",
        "                not_null = [el for el in df.columns if pd.notna(el)]\n",
        "\n",
        "                list_ipca.append(df[not_null])\n",
        "\n",
        "df = pd.concat(list_ipca)\n",
        "\n",
        "# Série temporal da gasolina em BH\n",
        "f_gas = df.categoria.str.lower().isin(['gasolina', 'gasolina ', ' gasolina'])\n",
        "tb_gas = df[f_gas].set_index('periodo')[['BH','NACIONAL']]\n",
        "tb_gas['item'] = 'gasolina'\n",
        "\n",
        "# Série temporal do indice geral do IPCA em BH\n",
        "f_ger = df.categoria.str.lower().isin([el.lower() for el in indices])\n",
        "tb_ger = df[f_ger].set_index('periodo')[['BH','NACIONAL']]\n",
        "tb_ger['item'] = 'indice geral'\n",
        "\n",
        "df_ipca = pd.concat([tb_ger, tb_gas])\n",
        "\n",
        "df_ipca = df_ipca.reset_index()\n",
        "df_ipca = df_ipca.melt(\n",
        "                id_vars=['periodo','item'], \n",
        "                value_vars=['BH','NACIONAL'],\n",
        "                var_name='abrangencia',\n",
        "                value_name = 'indice'\n",
        "                )\n",
        "\n",
        "# Montar uma tabela com a estrutura \n",
        "# periodo | abrangencia | gasolina | indice geral\n",
        "df_ipca = df_ipca.pivot_table('indice', \n",
        "                              ['periodo', 'abrangencia'], \n",
        "                              'item', \n",
        "                              'sum')\n",
        "\n",
        "df_ipca.index.names = ['data','abrangencia']\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data'\n",
        "df_ipca.to_csv(path + '/ipca.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WCRrDZr5tS4",
        "colab_type": "code",
        "outputId": "afa97ab7-7832-4b97-ce4b-228fe7052574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data'\n",
        "df_ipca = pd.read_csv(path + '/ipca.csv', \n",
        "                      parse_dates=['periodo'],\n",
        "                      index_col = [0,1])\n",
        "\n",
        "def acumulado(Series):\n",
        "    a = 1\n",
        "    for v in Series.dropna().values:\n",
        "        a = a + a*float(v)/100\n",
        "    return round((a-1)*100, 2)\n",
        "\n",
        "ano_a_ano = []\n",
        "f_nacional = df_ipca.reset_index()['abrangencia'] == 'NACIONAL'\n",
        "\n",
        "for ano in range(2006,2021):\n",
        "    f_date = df_ipca.reset_index()['periodo'].dt.year == ano\n",
        "\n",
        "    ff = f_nacional & f_date\n",
        "\n",
        "    s_ = df_ipca[ff.values].agg(acumulado)\n",
        "    dif = (s_.gasolina/s_['indice geral'])\n",
        "    ano_a_ano.append(\n",
        "        {'ano':ano,\n",
        "         'gasolina': s_.gasolina,\n",
        "         'geral': s_['indice geral'],\n",
        "         'diff':dif}\n",
        "    )\n",
        "\n",
        "pd.DataFrame(ano_a_ano)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ano</th>\n",
              "      <th>gasolina</th>\n",
              "      <th>geral</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006</td>\n",
              "      <td>2.49</td>\n",
              "      <td>3.14</td>\n",
              "      <td>0.792994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>4.46</td>\n",
              "      <td>-0.152466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008</td>\n",
              "      <td>-0.26</td>\n",
              "      <td>5.90</td>\n",
              "      <td>-0.044068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009</td>\n",
              "      <td>2.06</td>\n",
              "      <td>4.31</td>\n",
              "      <td>0.477958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010</td>\n",
              "      <td>1.67</td>\n",
              "      <td>5.91</td>\n",
              "      <td>0.282572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011</td>\n",
              "      <td>6.93</td>\n",
              "      <td>6.50</td>\n",
              "      <td>1.066154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2012</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>5.84</td>\n",
              "      <td>-0.066781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2013</td>\n",
              "      <td>6.51</td>\n",
              "      <td>5.91</td>\n",
              "      <td>1.101523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2014</td>\n",
              "      <td>2.89</td>\n",
              "      <td>6.41</td>\n",
              "      <td>0.450858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2015</td>\n",
              "      <td>20.10</td>\n",
              "      <td>10.67</td>\n",
              "      <td>1.883786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2016</td>\n",
              "      <td>2.53</td>\n",
              "      <td>6.29</td>\n",
              "      <td>0.402226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2017</td>\n",
              "      <td>10.31</td>\n",
              "      <td>2.95</td>\n",
              "      <td>3.494915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2018</td>\n",
              "      <td>7.25</td>\n",
              "      <td>3.75</td>\n",
              "      <td>1.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2019</td>\n",
              "      <td>4.01</td>\n",
              "      <td>4.31</td>\n",
              "      <td>0.930394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ano  gasolina  geral      diff\n",
              "0   2006      2.49   3.14  0.792994\n",
              "1   2007     -0.68   4.46 -0.152466\n",
              "2   2008     -0.26   5.90 -0.044068\n",
              "3   2009      2.06   4.31  0.477958\n",
              "4   2010      1.67   5.91  0.282572\n",
              "5   2011      6.93   6.50  1.066154\n",
              "6   2012     -0.39   5.84 -0.066781\n",
              "7   2013      6.51   5.91  1.101523\n",
              "8   2014      2.89   6.41  0.450858\n",
              "9   2015     20.10  10.67  1.883786\n",
              "10  2016      2.53   6.29  0.402226\n",
              "11  2017     10.31   2.95  3.494915\n",
              "12  2018      7.25   3.75  1.933333\n",
              "13  2019      4.01   4.31  0.930394\n",
              "14  2020       NaN    NaN       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4L4MLKNTtWo",
        "colab_type": "text"
      },
      "source": [
        "## Dados das cidades\n",
        "\n",
        "\n",
        "Podemos usar os dados do Atlas Brasil. Como o site proíbe o o scrape por robôs, estou usando uma cópia da planilha oferecida, acessada em 8/3/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVKYiVIeW3nH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive/EAD/PUC Minas/13 - TCC/data/raw'\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "list_dfs = pd.read_excel('atlas2013_dadosbrutos_pt.xlsx', sheet_name=None)\n",
        "\n",
        "df_mun = list_dfs['MUN 91-00-10']\n",
        "df_est = list_dfs['UF 91-00-10']\n",
        "df_bra = list_dfs['BR 91-00-10']\n",
        "\n",
        "# Escrevendo csv\n",
        "df_mun.to_csv('geo_municipios.csv', index=False)\n",
        "df_est.to_csv('geo_estados.csv', index=False)\n",
        "df_bra.to_csv('geo_brasil.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKZhX6jydZO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}